# Toxic Comment Detection

## ğŸ“Œ Project Overview
This project focuses on **detecting toxic comments** using **Deep Learning**. A **Bidirectional LSTM** model was trained on a dataset of comments to classify toxicity. The model was built using **TensorFlow and Keras**, with **TextVectorization** for preprocessing.

## ğŸ“Š Dataset
- The dataset consists of **toxic and non-toxic** comments.
- Labels indicate **various types of toxicity** (e.g., insult, hate speech, threat).
- Preprocessing includes text cleaning, tokenization, and vectorization.

## ğŸš€ Model Architecture
- **TextVectorization:** Converts text to numerical format.
- **Embedding Layer:** Creates word embeddings.
- **Bidirectional LSTM:** Captures long-range dependencies.
- **Dropout Layers:** Prevent overfitting.
- **Dense Layers:** Final classification layers.
- **Activation:** Sigmoid for multi-label classification.

## ğŸ”§ Installation & Setup
### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/moussalasfar/InternIntelligence_toxicCommentClassification.git
cd InternIntelligence_toxicCommentClassification
```

## ğŸ‘¨â€ğŸ’» Author
**moussa Lasfar**  
[LinkedIn](https://www.linkedin.com/in/moussa-lasfar-423793196/)


