# Toxic Comment Detection

## 📌 Project Overview
This project focuses on **detecting toxic comments** using **Deep Learning**. A **Bidirectional LSTM** model was trained on a dataset of comments to classify toxicity. The model was built using **TensorFlow and Keras**, with **TextVectorization** for preprocessing.

## 📊 Dataset
- The dataset consists of **toxic and non-toxic** comments.
- Labels indicate **various types of toxicity** (e.g., insult, hate speech, threat).
- Preprocessing includes text cleaning, tokenization, and vectorization.

## 🚀 Model Architecture
- **TextVectorization:** Converts text to numerical format.
- **Embedding Layer:** Creates word embeddings.
- **Bidirectional LSTM:** Captures long-range dependencies.
- **Dropout Layers:** Prevent overfitting.
- **Dense Layers:** Final classification layers.
- **Activation:** Sigmoid for multi-label classification.

## 🔧 Installation & Setup
### 1️⃣ Clone the Repository
```bash
git clone https://github.com/moussalasfar/InternIntelligence_toxicCommentClassification.git
cd InternIntelligence_toxicCommentClassification
```

## 👨‍💻 Author
**moussa Lasfar**  
[LinkedIn](https://www.linkedin.com/in/moussa-lasfar-423793196/)


